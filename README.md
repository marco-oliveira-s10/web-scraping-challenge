# Web Scraping Platform

## ğŸŒ VisÃ£o Geral do Projeto

Este projeto Ã© uma plataforma de web scraping desenvolvida em Laravel, projetada para coletar, gerenciar e visualizar produtos de diferentes categorias de forma automatizada e eficiente.

### ğŸ” Fonte de Dados: WebScraper.io

O projeto utiliza o site https://webscraper.io/test-sites/e-commerce/allinone, uma pÃ¡gina de demonstraÃ§Ã£o especificamente criada para testes e prÃ¡tica de web scraping. Este site simula um ambiente de e-commerce completo com caracterÃ­sticas tÃ­picas de lojas online reais.

#### CaracterÃ­sticas Principais do Site de DemonstraÃ§Ã£o:
* ğŸ·ï¸ Produtos organizados em categorias (computadores, telefones, tablets, monitores)
* ğŸ“¸ Listagens de produtos com imagens, preÃ§os e descriÃ§Ãµes detalhadas
* ğŸ§­ Estrutura de navegaÃ§Ã£o com menus e submenus
* ğŸ“„ Elementos de paginaÃ§Ã£o
* ğŸ”¬ Detalhes de produtos para anÃ¡lise

#### PropÃ³sito do Projeto
O objetivo deste projeto Ã© demonstrar tÃ©cnicas de web scraping em um ambiente seguro e legal, utilizando um site de teste projetado especificamente para desenvolvedores. Foi desenvolvido como um desafio tÃ©cnico para avaliar habilidades de scraping em diferentes nÃ­veis de complexidade (JÃºnior, Pleno e SÃªnior).

## âœ¨ Principais Funcionalidades

### ğŸ•·ï¸ Scraping Automatizado
- Coleta de produtos de mÃºltiplas categorias
- Agendamento automÃ¡tico de scraping
- Suporte a diferentes fontes de dados

### ğŸ“Š Painel Administrativo
- VisualizaÃ§Ã£o de produtos coletados
- Gerenciamento de logs de scraping
- Monitoramento de status do sistema

### ğŸ” Recursos Principais
- Coleta de produtos em tempo real
- CategorizaÃ§Ã£o automÃ¡tica
- Cache inteligente
- Registro detalhado de operaÃ§Ãµes

## ğŸ› ï¸ Requisitos do Sistema

- PHP 8.1+
- Composer
- PostgreSQL 16
- Node.js (para frontend) (removido)
- Git

## ğŸš€ InstalaÃ§Ã£o Passo a Passo

### 1. Clonar o RepositÃ³rio
```bash
git clone https://github.com/seu-usuario/web-scraping-platform.git
cd web-scraping-platform
```

### 2. Configurar Ambiente
```bash
# Copiar arquivo de configuraÃ§Ã£o
cp .env.example .env

# Configurar banco de dados PostgreSQL no .env
# Edite as configuraÃ§Ãµes:
# DB_CONNECTION=pgsql
# DB_HOST=127.0.0.1
# DB_PORT=5432
# DB_DATABASE=seu_banco_de_dados
# DB_USERNAME=seu_usuario
# DB_PASSWORD=sua_senha

# Instalar dependÃªncias do PHP
composer install

# Instalar dependÃªncias do frontend
npm install

# Gerar chave da aplicaÃ§Ã£o
php artisan key:generate
```

### 3. Configurar Banco de Dados PostgreSQL
```bash
# Criar banco de dados (se ainda nÃ£o existir)
# VocÃª pode usar o psql ou qualquer client PostgreSQL
createdb seu_banco_de_dados

# Rodar migraÃ§Ãµes
php artisan migrate

# Popular dados iniciais
php artisan db:seed
```

### DependÃªncias EspecÃ­ficas do PostgreSQL
Certifique-se de ter instalado:
```bash
# ExtensÃµes PHP para PostgreSQL
sudo apt-get install php-pgsql        # Para sistemas baseados em Debian/Ubuntu
# ou
sudo yum install php-pgsql             # Para CentOS/RHEL

# ExtensÃ£o Postgres para Laravel
composer require doctrine/dbal
```

### 4. Configurar Scraping
```bash
# Criar comando de scraping
php artisan make:command ScrapeProdutos

# Configurar agendamento no Kernel.php
# $schedule->command('product:fetch')->everyTwoMinutes();
```

### 5. Rodar a AplicaÃ§Ã£o
```bash
# Iniciar servidor local
php artisan serve

# Compilar assets
npm run dev

# Para produÃ§Ã£o
npm run build
```

## ğŸ•°ï¸ Agendamento de Scraping

### MÃ©todo 1: Laravel Schedule (Recomendado)
```bash
# Rodar schedule a cada 2 minutos
php artisan schedule:run
```

### MÃ©todo 2: Windows Batch Script (Simulando CronJob)
```batch
@echo off
:loop
php artisan schedule:run
timeout /t 120 /nobreak
goto loop
```

## ğŸ”’ ConfiguraÃ§Ãµes de SeguranÃ§a

- Utilize autenticaÃ§Ã£o de admin (Tela login)
- Proteja rotas sensÃ­veis

## ğŸ“‹ Comandos Ãšteis

```bash
# Limpar caches
php artisan config:clear
php artisan cache:clear

# Rodar testes
php artisan test

# Verificar status do schedule
php artisan schedule:list
```

## ğŸ› SoluÃ§Ã£o de Problemas

- Verifique logs em `storage/logs/laravel.log`
- Confirme configuraÃ§Ãµes do `.env`
- Garanta permissÃµes de diretÃ³rio

## ğŸ¤ ContribuiÃ§Ã£o

1. FaÃ§a um Fork do projeto
2. Crie sua Feature Branch (`git checkout -b feature/NovaFuncionalidade`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona NovaFuncionalidade'`)
4. Push para a Branch (`git push origin feature/NovaFuncionalidade`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

DistribuÃ­do sob a licenÃ§a MIT. Veja `LICENSE` para mais informaÃ§Ãµes.

## ğŸ“ Contato

Marco Oliveira - marco.oliveira.s10@gmail.com

Link do Projeto: [https://github.com/marco-oliveira-s10/web-scraping-challenge]
